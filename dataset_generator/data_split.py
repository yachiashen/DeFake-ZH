import os
import random
import re
import pandas as pd
from sklearn.model_selection import train_test_split

PROJECT_FOLDER = os.path.join(os.path.dirname(os.path.dirname(__file__)))
DATASET_FOLDER = os.path.join(PROJECT_FOLDER, 'data', 'dataset')

if __name__ == '__main__':

    true_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'news', 'true_news.csv'))            # news from relatively credible sources
    kknews_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'news', 'kknews.csv'))             # news from kknews (content farm)
    read01_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'news', 'read01.csv'))             # news from read01 (content farm)
    mgp_fake_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'news', 'mgp_fake_news.csv'))    # fake news verified by MGP
    llm_fake_df = pd.read_csv(os.path.join(DATASET_FOLDER, 'news', 'llm_fake_news.csv'))    # fake news generated by llama3.1-8B-Instruct

    train_df, test_df = pd.DataFrame(columns = 'Title,Content,Label'.split(',')), pd.DataFrame(columns = 'Title,Content,Label'.split(',')) 
    train_df_idx, test_df_idx = 0, 0

    ### split train and test data

    #######################################################################

    ## true news
    train_indices, test_indices = train_test_split(
        range(len(true_df.index)),
        train_size = 0.85,
        shuffle = True,
    )

    train_indices = random.sample(train_indices, 5000)
    print(f'true_news: {len(train_indices)} {len(test_indices)}')

    # delete journalist information from cna data, e.g. "（中央社記者姜宜菁雲林縣20日電）", "（編輯:陳鎧妤）"
    for i in train_indices:
        train_df.loc[train_df_idx, 'Title'] = true_df.loc[i, '新聞標題']
        text = true_df.loc[i, '新聞內容']
        text = re.sub(r'^（.{,20}）', '', text.strip())
        text = re.sub(r'（編輯：.*）', '', text)
        text = re.sub(r'（譯者：.*）', '', text)
        train_df.loc[train_df_idx, 'Content'] = text.strip()
        train_df.loc[train_df_idx, 'Label'] = 0
        train_df_idx += 1

    for i in test_indices:
        test_df.loc[test_df_idx, 'Title'] = true_df.loc[i, '新聞標題']
        test_df.loc[test_df_idx, 'Content'] = true_df.loc[i, '新聞內容']
        test_df.loc[test_df_idx, 'Label'] = 0
        test_df_idx += 1

    #######################################################################

    ## mgp
    train_indices, test_indices = train_test_split(
        range(len(mgp_fake_df.index)),
        train_size = 0.85,
        shuffle = True,
    )
    print(f'mgp_fake_news: {len(train_indices)} {len(test_indices)}')
    for i in train_indices:
        train_df.loc[train_df_idx, 'Title'] = mgp_fake_df.loc[i, 'Title']
        train_df.loc[train_df_idx, 'Content'] = mgp_fake_df.loc[i, 'Content']
        train_df.loc[train_df_idx, 'Label'] = 1
        train_df_idx += 1

    for i in test_indices:
        test_df.loc[test_df_idx, 'Title'] = mgp_fake_df.loc[i, 'Title']
        test_df.loc[test_df_idx, 'Content'] = mgp_fake_df.loc[i, 'Content']
        test_df.loc[test_df_idx, 'Label'] = 1
        test_df_idx += 1

    #######################################################################

    # ## kknews
    # train_indices, test_indices = train_test_split(
    #     range(len(kknews_df.index)),
    #     train_size = 0.85,
    #     shuffle = True,
    # )
    # print(f'kknews: {len(train_indices)} {len(test_indices)}')
    # for i in train_indices:
    #     train_df.loc[train_df_idx, 'Title'] = kknews_df.loc[i, 'Title']
    #     train_df.loc[train_df_idx, 'Content'] = kknews_df.loc[i, 'Content']
    #     train_df.loc[train_df_idx, 'Label'] = 1
    #     train_df_idx += 1

    # for i in test_indices:
    #     test_df.loc[test_df_idx, 'Title'] = kknews_df.loc[i, 'Title']
    #     test_df.loc[test_df_idx, 'Content'] = kknews_df.loc[i, 'Content']
    #     test_df.loc[test_df_idx, 'Label'] = 1
    #     test_df_idx += 1

    #######################################################################

    # ## read01
    # train_indices, test_indices = train_test_split(
    #     range(len(read01_df.index)),
    #     train_size = 0.85,
    #     shuffle = True,
    # )
    # print(f'read01: {len(train_indices)} {len(test_indices)}')
    # for i in train_indices:
    #     train_df.loc[train_df_idx, 'Title'] = read01_df.loc[i, 'Title']
    #     train_df.loc[train_df_idx, 'Content'] = read01_df.loc[i, 'Content']
    #     train_df.loc[train_df_idx, 'Label'] = 1
    #     train_df_idx += 1

    # for i in test_indices:
    #     test_df.loc[test_df_idx, 'Title'] = read01_df.loc[i, 'Title']
    #     test_df.loc[test_df_idx, 'Content'] = read01_df.loc[i, 'Content']
    #     test_df.loc[test_df_idx, 'Label'] = 1
    #     test_df_idx += 1

    #######################################################################

    ## llm
    train_indices, test_indices = train_test_split(
        range(len(llm_fake_df.index)),
        train_size = 0.85,
        shuffle = True,
    )
    print(f'llm_fake_news: {len(train_indices)} {len(test_indices)}')
    for i in train_indices:
        train_df.loc[train_df_idx, 'Title'] = llm_fake_df.loc[i, '反向新聞標題']
        train_df.loc[train_df_idx, 'Content'] = llm_fake_df.loc[i, '反向新聞內容']
        train_df.loc[train_df_idx, 'Label'] = 1
        train_df_idx += 1

    for i in test_indices:
        test_df.loc[test_df_idx, 'Title'] = llm_fake_df.loc[i, '反向新聞標題']
        test_df.loc[test_df_idx, 'Content'] = llm_fake_df.loc[i, '反向新聞內容']
        test_df.loc[test_df_idx, 'Label'] = 1
        test_df_idx += 1

    #######################################################################

    train_df.to_csv(os.path.join(DATASET_FOLDER, 'news', 'train_news.csv'), index = False)
    test_df.to_csv(os.path.join(DATASET_FOLDER, 'news', 'test_news.csv'), index = False)

        