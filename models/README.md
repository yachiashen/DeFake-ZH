<p align="center">
  <a href="README.md"><img src="https://img.shields.io/badge/lang-English-blue.svg"></a>
  <a href="README.zh-TW.md"><img src="https://img.shields.io/badge/lang-繁體中文-green.svg"></a>
</p>

# models Directory Description

This project uses several NLP pre-trained models and vector representation models.  
Please download the corresponding model weights as described below and place them in the specified folders to ensure compatibility and reproducibility.

> Note: Some models will be automatically downloaded to the user's Hugging Face cache.  
> If you want to fix the storage path or perform offline deployment, please create the corresponding folders in advance and download the models locally.

---

## Directory Structure

```bash
models/
├── bge-m3/                  # Multilingual sentence embedding model (FlagEmbedding, BGE‑M3)
├── chinese-macbert-large/   # Chinese MacBERT (HFL)
├── ltp/                     # HIT‑SCIR NLP toolkit (tokenization/NER/SRL)
├── task/                    # Project-specific trained classifiers (.pt files)
├── text2vec/                # Chinese sentence embedding model
└── word2vec/                # Chinese word embeddings (via text2vec.Word2Vec)
```

---

### bge-m3

- **Purpose**: Multilingual sentence embeddings (retrieval/similarity), loaded via `FlagEmbedding.BGEM3FlagModel`.
- **Code references**: `nodes.py`, `featureEngineering.py` use `BGEM3FlagModel`.
- **Recommended source**: [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3/tree/main)
- **Reference commit (for reproducibility)**: `5617a9f61b028005a4858fdac845db406aefb181`
- **Placement**: Download into `models/bge-m3/` or configure path in code.

---

### chinese-macbert-large

- **Purpose**: Extract Chinese contextual embeddings; loaded with `transformers` (`BertTokenizer/BertModel`).
- **Code references**: `featureEngineering.py` and related files.
- **Recommended source**: [hfl/chinese-macbert-large](https://huggingface.co/hfl/chinese-macbert-large)
- **Reference commit (for reproducibility)**: `1cf2677c782975600ce58e2961656b1b29eddbae`
- **Placement**: By default, it will be automatically downloaded into Hugging Face cache.  
  For offline or fixed-version use, manually download into `models/chinese-macbert-large/`.

---

### ltp

- **Purpose**: Chinese word segmentation, named entity recognition, semantic role labeling, etc.
- **Code references**: `contradiction.py`, `nodes.py` use `LTP(LTP_MODEL_PATH)`.
- **Recommended source**: [HIT-SCIR/LTP](https://github.com/HIT-SCIR/ltp)  pre-trained models (follow official release).
- **Placement**: Place downloaded models into `models/ltp/`.  
  If not provided locally, the code may attempt to download them online.

---

### task (project-trained classifiers)

- **Contents**:
  - `title_model.pt`: classifier trained on news titles (sentiment/subjectivity etc.)  
  - `content_model.pt`: classifier trained on news content (sentiment/subjectivity etc.)  
  - `mlp_model.pt`: final MLP classifier combining features  
- **Code references**: `classifier.py`, `scores.py`, etc.
- **Placement**: `models/task/` (already included in repo or generated by training scripts).

---

### text2vec

- **Purpose**: Chinese sentence embedding model (optional).  
  The main sentence embedding method in this project is **BGE‑M3**, while text2vec can serve as a backup or auxiliary.
- **Code references**: `const.py` includes `TEXT2VEC_MODEL_PATH` constant; optional in practice.
- **Recommended source**: [shibing624/text2vec-base-chinese](https://huggingface.co/shibing624/text2vec-base-chinese)
- **Placement**: `models/text2vec/` (if this route is used).

---

### word2vec (downloaded via text2vec.Word2Vec)

- **Purpose**: Word-level embeddings, used for similarity calculation and filtering of entities/phrases.  
- **Implementation (from source code)**: In `nodes.py`, the project imports from `text2vec`:
  ```python
  from text2vec import Word2Vec

  # Default: use Hugging Face cache
  word_model = Word2Vec("w2v-light-tencent-chinese")

  # Specify custom cache folder (recommended: models/word2vec/)
  word_model = Word2Vec("w2v-light-tencent-chinese", cache_folder="models/word2vec")
  ```
  The `"w2v-light-tencent-chinese"` identifier will be automatically resolved by the **text2vec** library, which downloads the model from Hugging Face into cache or the given `cache_folder`.
- **Placement**: For fixed version and path, create `models/word2vec/` and set `cache_folder` accordingly.

---

## Version Fixing & Offline Usage

- To prevent future incompatibility, **pin model versions or commit IDs** (especially for `bge-m3`, `macbert`, and `ltp`).  
- For offline or reproducible experiments:  
  1. Download models into fixed local folders (`models/...`).  
  2. Configure your code to point to these folders.  
  3. Record the actual **commit/version** used in your paper or README (reference commits provided above).

> License and Terms: Please comply with the original license and usage policies of each model.
